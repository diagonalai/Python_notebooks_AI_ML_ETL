{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2b34f8-af46-4b5a-8091-856f3997a4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.groq.com/keys'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from litellm import completion\n",
    "from typing import List, Dict\n",
    "'''https://console.groq.com/keys'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33452b14-51e6-4dc1-8cef-b6eb503463b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['GROQ_API_KEY'] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7ba92d-186d-4afe-917b-c41bf2388a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "    response = completion(\n",
    "        model=\"groq/meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
    "    \"\"\"Extract code block from response\"\"\"\n",
    "\n",
    "    if not '```' in response:\n",
    "        return response\n",
    "\n",
    "    code_block = response.split('```')[1].strip()\n",
    "\n",
    "    if code_block.startswith(block_type):\n",
    "        code_block = code_block[len(block_type):].strip()\n",
    "\n",
    "    return code_block\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_action(response: str) -> Dict:\n",
    "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
    "    try:\n",
    "        response = extract_markdown_block(response, \"action\")\n",
    "        response_json = json.loads(response)\n",
    "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
    "            return response_json\n",
    "        else:\n",
    "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e150b6fc-177b-4831-9d0b-82bdb8dc6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### DEFINE FUNCTIONS############\n",
    "\n",
    "def half(value: int):\n",
    "    halfvalue=value/2\n",
    "    return halfvalue\n",
    "\n",
    "def double(value: int):\n",
    "    doublevalue=value*2\n",
    "    return doublevalue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b6981b-b17e-429d-b655-d63cc2bfdf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What would you like me to do?  i need to know what is half of ten\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent thinking...\n",
      "Agent response: <Stop and think step by step. The user wants to know what is half of ten. This can be achieved by using the \"half\" tool. The input for the \"half\" tool is an integer, which in this case is 10. Parameters map to args, so I need to pass 10 as the input to the \"half\" tool.>\n",
      "\n",
      "```action\n",
      "{\n",
      " \"tool_name\": \"half\",\n",
      " \"args\": {\n",
      " \"input\": 10\n",
      " }\n",
      "}\n",
      "```\n",
      "Action result: {'result': 5.0}\n",
      "ITERATIONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN : 0\n",
      "Agent thinking...\n",
      "Agent response: <Stop and think step by step. The \"half\" tool has provided the result, which is 5.0. Now I need to terminate the conversation by using the \"terminate\" tool and provide a summary message to the user. The summary message will be \"Half of 10 is 5.0\".>\n",
      "\n",
      "```action\n",
      "{\n",
      " \"tool_name\": \"terminate\",\n",
      " \"args\": {\n",
      " \"message\": \"Half of 10 is 5.0\"\n",
      " }\n",
      "}\n",
      "```\n",
      "Half of 10 is 5.0\n"
     ]
    }
   ],
   "source": [
    "# Define system instructions (Agent Rules)\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are an AI agent that can perform tasks by using available tools.\n",
    "\n",
    "Available tools:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"half\": {\n",
    "        \"description\": \"Takes an input integer and divides by two.\",\n",
    "        \"parameters\": {\n",
    "            \"input\": {\n",
    "                \"type\": \"integer\"\n",
    "                \"description\" : \"The integer that is going to be divided by two.\"\n",
    "        }\n",
    "    },\n",
    "    \"double\": {\n",
    "        \"description\": \"Takes an input integer and multiplies by two.\",\n",
    "        \"parameters\": {\n",
    "            \"file_name\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The integer that is going to be multiplied by two\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \"terminate\": {\n",
    "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
    "        \"parameters\": {\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Summary message to return to the user.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The user will input an integer and what operation they want to do. If the tool is not available, just terminate.\n",
    "\n",
    "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
    "\n",
    "Important!!! Every response MUST have an action.\n",
    "You must ALWAYS respond in this format:\n",
    "\n",
    "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
    "\n",
    "```action\n",
    "{\n",
    "    \"tool_name\": \"insert tool_name\",\n",
    "    \"args\": {...fill in any required arguments here...}\n",
    "}\n",
    "```\"\"\"\n",
    "}]\n",
    "\n",
    "# Initialize agent parameters\n",
    "iterations = 0\n",
    "max_iterations = 10\n",
    "\n",
    "user_task = input(\"What would you like me to do? \")\n",
    "\n",
    "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
    "\n",
    "# The Agent Loop\n",
    "while iterations < max_iterations:\n",
    "    # 1. Construct prompt: Combine agent rules with memory\n",
    "    prompt = agent_rules + memory\n",
    "\n",
    "    # 2. Generate response from LLM\n",
    "    print(\"Agent thinking...\")\n",
    "    response = generate_response(prompt)\n",
    "    print(f\"Agent response: {response}\")\n",
    "\n",
    "    # 3. Parse response to determine action\n",
    "    action = parse_action(response)\n",
    "    result = \"Action executed\"\n",
    "\n",
    "    if action[\"tool_name\"] == \"half\":\n",
    "        result = {\"result\": half(action[\"args\"][\"input\"])}\n",
    "    elif action[\"tool_name\"] == \"double\":\n",
    "        result = {\"result\": double(action[\"args\"][\"input\"])}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################ADD MORE TOOLS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    elif action[\"tool_name\"] == \"error\":\n",
    "        result = {\"error\": action[\"args\"][\"message\"]}\n",
    "    elif action[\"tool_name\"] == \"terminate\":\n",
    "        print(action[\"args\"][\"message\"])\n",
    "        break\n",
    "    else:\n",
    "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
    "\n",
    "    print(f\"Action result: {result}\")\n",
    "\n",
    "    # 5. Update memory with response and results\n",
    "    memory.extend([\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
    "    ])\n",
    "\n",
    "    # 6. Check termination condition\n",
    "    if action[\"tool_name\"] == \"terminate\":\n",
    "        break\n",
    "    print(\"ITERATIONNNNNNNNN :\", iterations)\n",
    "    iterations += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765e83c-f68b-4fd9-aead-804cf1a1a07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
